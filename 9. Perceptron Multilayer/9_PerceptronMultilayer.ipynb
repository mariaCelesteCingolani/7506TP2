{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/celeste/anaconda3/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.30.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /home/celeste/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/celeste/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/celeste/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/celeste/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/celeste/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/celeste/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/celeste/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/celeste/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/celeste/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/celeste/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/celeste/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras in /home/celeste/anaconda3/lib/python3.7/site-packages (2.4.3)\n",
      "Requirement already satisfied: h5py in /home/celeste/anaconda3/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/celeste/anaconda3/lib/python3.7/site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/celeste/anaconda3/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /home/celeste/anaconda3/lib/python3.7/site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: six in /home/celeste/anaconda3/lib/python3.7/site-packages (from h5py->keras) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/celeste/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/celeste/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/celeste/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#librer√≠as, no es necesario volverlas a importar\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, Sequential\n",
    "\n",
    "%run ../0_Data/Util.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset de entranamiento\n",
    "df_train = pd.read_csv(os.path.join('..','0_Data','dataset','train.csv'),index_col='id', encoding='utf8')\n",
    "\n",
    "#Dataset de test\n",
    "df_test = pd.read_csv(os.path.join('..','0_Data','dataset','test.csv'),index_col='id', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_original = df_train['text']\n",
    "x_test_original = df_test['text']\n",
    "train_y  = df_train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 200 # max number of words in a question to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 200, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 60000)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                600010    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 15,600,021\n",
      "Trainable params: 15,600,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/6\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.6786 - accuracy: 0.5774\n",
      "Epoch 2/6\n",
      "15/15 [==============================] - 3s 193ms/step - loss: 0.5605 - accuracy: 0.7261\n",
      "Epoch 3/6\n",
      "15/15 [==============================] - 3s 191ms/step - loss: 0.3913 - accuracy: 0.8609\n",
      "Epoch 4/6\n",
      "15/15 [==============================] - 3s 191ms/step - loss: 0.2362 - accuracy: 0.9281\n",
      "Epoch 5/6\n",
      "15/15 [==============================] - 3s 192ms/step - loss: 0.1320 - accuracy: 0.9664\n",
      "Epoch 6/6\n",
      "15/15 [==============================] - 3s 194ms/step - loss: 0.0752 - accuracy: 0.9831\n",
      "Training Accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(x_train_original))\n",
    "train_X = tokenizer.texts_to_sequences(x_train_original)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=max_features, \n",
    "                           output_dim=embed_size, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_X, train_y,\n",
    "                    epochs=6,\n",
    "                    batch_size=512)\n",
    "\n",
    "\n",
    "#model.fit(train_X, train_y, batch_size=512, epochs=2)\n",
    "loss, accuracy = model.evaluate(train_X, train_y, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "test_X = tokenizer.texts_to_sequences(x_test_original)\n",
    "\n",
    "## Pad the sentences \n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "\n",
    "#y_test = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "y_test = model.predict_classes(test_X, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_y = model.predict_classes(train_X, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4342\n",
      "           1       1.00      0.98      0.99      3271\n",
      "\n",
      "    accuracy                           0.99      7613\n",
      "   macro avg       0.99      0.99      0.99      7613\n",
      "weighted avg       0.99      0.99      0.99      7613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report: \\n{}\".format(classification_report(train_y, pred_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join('..','0_Data','dataset','sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3263"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       0\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"tensor_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
