{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7506 - Organizacion de Datos - TP N°2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/celeste/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/celeste/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/celeste/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#librerías, no es necesario volverlas a importar\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "util = os.path.join('..','0_Data','Util.ipynb')\n",
    "#Vectorizacion\n",
    "%run $util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train-validation-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join('..','dataset','train.csv'),index_col='id', encoding='utf8')\n",
    "df_test = pd.read_csv(os.path.join('..','dataset','test.csv'),index_col='id', encoding='utf8')\n",
    "\n",
    "#Le agregamos una columna de texto preprocesado para no tener que hacerlo varias veces\n",
    "df_train['texto_preprocesado_sentiment_analysis'] = df_train['text'].apply(lambda x: clean_text_sentiment_analysis(x))\n",
    "df_test['texto_preprocesado_sentiment_analysis'] = df_test['text'].apply(lambda x: clean_text_sentiment_analysis(x))\n",
    "\n",
    "#Creamos sets de training, validación y test randomizados\n",
    "#manteneniendo los pesos de cada clase en los splits\n",
    "temp_df, test_data = train_test_split(df_train, test_size=0.2, random_state=1, shuffle=True, stratify=df_train.target)\n",
    "train_data, val_data = train_test_split(temp_df, test_size=0.2, random_state=2, shuffle=True, stratify=temp_df.target)\n",
    "\n",
    "df_train2 = df_train.copy()\n",
    "df_train2.text = df_train2.texto_preprocesado_sentiment_analysis\n",
    "\n",
    "df_test2 = df_test.copy()\n",
    "df_test2.text = df_test2.texto_preprocesado_sentiment_analysis\n",
    "\n",
    "train_data2 = train_data.copy()\n",
    "train_data2.text = train_data2.texto_preprocesado_sentiment_analysis\n",
    "\n",
    "val_data2 = val_data.copy()\n",
    "val_data2.text = val_data2.texto_preprocesado_sentiment_analysis\n",
    "\n",
    "test_data2 = test_data.copy()\n",
    "test_data2.text = test_data2.texto_preprocesado_sentiment_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datos_originales_como_arrays:\n",
    "    def __init__(self):\n",
    "        self.x_train = train_data.text\n",
    "        self.y_train = train_data.target\n",
    "        self.x_val = val_data.text\n",
    "        self.y_val = val_data.target\n",
    "        self.x_test = test_data.text\n",
    "        self.y_test = test_data.target\n",
    "        self.predict = df_test.text\n",
    "\n",
    "class datos_originales_como_databases:\n",
    "    def __init__(self):\n",
    "        self.train = train_data.copy()\n",
    "        self.validation = val_data.copy()\n",
    "        self.test = test_data.copy()\n",
    "        self.predict = df_test.copy()\n",
    "        \n",
    "#Devolver los datos como arrays\n",
    "def get_data_original_as_np_array():    \n",
    "    return datos_originales_como_arrays()\n",
    "\n",
    "#Devolver los datos como databases\n",
    "def get_data_original_as_database():    \n",
    "    return datos_originales_como_databases()\n",
    "\n",
    "#ejemplo: data = get_data_original_as_np_array()\n",
    "#         model.fit(x=data.x_train, y=data.y_train,... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "source": [
    "## Datos Preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class datos_sentiment_analysis_como_np_arrays:\n",
    "    def __init__(self):        \n",
    "        self.x_train = train_data.texto_preprocesado_sentiment_analysis\n",
    "        self.y_train = train_data.target\n",
    "        self.x_val = val_data.texto_preprocesado_sentiment_analysis\n",
    "        self.y_val = val_data.target\n",
    "        self.x_test = test_data.texto_preprocesado_sentiment_analysis\n",
    "        self.y_test = test_data.target\n",
    "        self.predict = df_test.texto_preprocesado_sentiment_analysis\n",
    "\n",
    "class datos_sentiment_analysis_como_np_databases:\n",
    "    def __init__(self):\n",
    "        global train_data2\n",
    "        global val_data2\n",
    "        global test_data2\n",
    "        global df_test2\n",
    "        \n",
    "        self.train = train_data2\n",
    "        self.validation = val_data2\n",
    "        self.test = test_data2\n",
    "        self.predict = df_test2\n",
    "\n",
    "#Devolver los datos como arrays\n",
    "def get_data_sentiment_analysis_as_np_array():    \n",
    "    return datos_sentiment_analysis_como_np_arrays()\n",
    "\n",
    "#Devolver los datos como databases\n",
    "def get_data_sentiment_analysis_as_database():    \n",
    "    return datos_sentiment_analysis_como_np_databases()\n",
    "\n",
    "\n",
    "#ejemplo: data = get_data_sentiment_analysis_as_np_array()\n",
    "#         model.fit(x=data.x_train, y=data.y_train,... \n",
    "#         model.evaluate(data.test_x, data.test_y)\n",
    "# model.predict(predict,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. K-Fold Cross Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "class datos_originales_k_fold_como_arrays:\n",
    "    def __init__(self, train_data=None, val_data=None):\n",
    "        self.x_train = train_data.text\n",
    "        self.y_train = train_data.target\n",
    "        self.x_val = val_data.text\n",
    "        self.y_val = val_data.target\n",
    "\n",
    "def convertir_a_formato_objeto(train_index, validation_index, train_database):\n",
    "    entrenamiento = train_database.iloc[train_index]\n",
    "    validacion = train_database.iloc[validation_index]\n",
    "    data = datos_originales_k_fold_como_arrays(train_data=entrenamiento, val_data=validacion)    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos sets de training, validación y test randomizados\n",
    "#manteneniendo los pesos de cada clase en los splits\n",
    "    \n",
    "#Devuelve el split, la base de datos de entrenamiento y la base de datos para predecir\n",
    "def get_k_folded_data_original_as_np_array():    \n",
    "    split = kf.split(X = df_train.drop('target', axis=1), y=df_train.target)\n",
    "    return split, df_train.copy(), df_test.text\n",
    "\n",
    "def get_k_folded_data_original_as_database():    \n",
    "    split = kf.split(X = df_train.drop('target', axis=1), y=df_train.target)\n",
    "    return split, df_train.copy(), df_test.copy()\n",
    "\n",
    "# ejemplo: \n",
    "# split, df_train, predict = get_k_folded_data_original_as_np_array()\n",
    "# for train_index, validation_index in split:\n",
    "#         data = convertir_a_formato_objeto(train_index, validation_index, df_train)\n",
    "#         model.fit(x=data.x_train, y=data.y_train,... \n",
    "#         model.evaluate(data.test_x, data.test_y)    \n",
    "#     ...\n",
    "# model.predict(predict,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos Preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Devuelve el split, la base de datos de entrenamiento y la base de datos para predecir\n",
    "def get_k_folded_data_sentiment_analysis_as_np_array():    \n",
    "    split = kf.split(X = df_train2.drop('target', axis=1), y=df_train2.target)\n",
    "    return split, df_train2, df_test2.text\n",
    "\n",
    "def get_k_folded_data_sentiment_analysis_as_database():    \n",
    "    split = kf.split(X = df_train2.drop('target', axis=1), y=df_train2.target)\n",
    "    return split, df_train2, df_test2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
