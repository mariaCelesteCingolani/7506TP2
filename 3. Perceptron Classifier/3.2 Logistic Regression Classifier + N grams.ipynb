{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.79 s\n",
      "Wall time: 2.86 s\n"
     ]
    }
   ],
   "source": [
    "#Llamar al dataloader\n",
    "%run ../0_Data/0_DataLoaderBOW_TFIDF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "#Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "#Tuning de Parametros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Clasificador\n",
    "from sklearn.linear_model import LogisticRegression # Classifier using Logistic Regression.\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Casos básicos de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 s, sys: 63.6 ms, total: 2.82 s\n",
      "Wall time: 41.3 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4342\n",
      "           1       0.99      0.93      0.96      3271\n",
      "\n",
      "    accuracy                           0.96      7613\n",
      "   macro avg       0.97      0.96      0.96      7613\n",
      "weighted avg       0.97      0.96      0.96      7613\n",
      "\n",
      "Mejor Score:  0.7323055246621449\n",
      "Mejores Parametros:  {'clf__C': 0.2, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.1,1.1,0.1),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 642 ms, sys: 17.1 ms, total: 659 ms\n",
      "Wall time: 9.04 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      4342\n",
      "           1       0.91      0.75      0.82      3271\n",
      "\n",
      "    accuracy                           0.86      7613\n",
      "   macro avg       0.87      0.85      0.85      7613\n",
      "weighted avg       0.87      0.86      0.86      7613\n",
      "\n",
      "Mejor Score:  0.7313841292904333\n",
      "Mejores Parametros:  {'clf__C': 0.06999999999999999, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.06,0.08,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "%time clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4342\n",
      "           1       0.99      0.96      0.97      3271\n",
      "\n",
      "    accuracy                           0.98      7613\n",
      "   macro avg       0.98      0.98      0.98      7613\n",
      "weighted avg       0.98      0.98      0.98      7613\n",
      "\n",
      "Mejor Score:  0.7154919357413224\n",
      "Mejores Parametros:  {'clf__C': 4.2, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(4,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('vectorizador',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                   input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                   min_df=5, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                   smooth_idf=True, stop_words='english', strip_accents='unicode',\n",
       "                   sublinear_tf=False, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                   use_idf=True, vocabulary=None)),\n",
       "  ('clf',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                      multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                      warm_start=False))],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__vectorizador': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                 min_df=5, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words='english', strip_accents='unicode',\n",
       "                 sublinear_tf=False, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                 use_idf=True, vocabulary=None),\n",
       " 'estimator__clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'estimator__vectorizador__analyzer': 'word',\n",
       " 'estimator__vectorizador__binary': False,\n",
       " 'estimator__vectorizador__decode_error': 'strict',\n",
       " 'estimator__vectorizador__dtype': numpy.float64,\n",
       " 'estimator__vectorizador__encoding': 'utf-8',\n",
       " 'estimator__vectorizador__input': 'content',\n",
       " 'estimator__vectorizador__lowercase': True,\n",
       " 'estimator__vectorizador__max_df': 1.0,\n",
       " 'estimator__vectorizador__max_features': None,\n",
       " 'estimator__vectorizador__min_df': 5,\n",
       " 'estimator__vectorizador__ngram_range': (1, 1),\n",
       " 'estimator__vectorizador__norm': 'l2',\n",
       " 'estimator__vectorizador__preprocessor': None,\n",
       " 'estimator__vectorizador__smooth_idf': True,\n",
       " 'estimator__vectorizador__stop_words': 'english',\n",
       " 'estimator__vectorizador__strip_accents': 'unicode',\n",
       " 'estimator__vectorizador__sublinear_tf': False,\n",
       " 'estimator__vectorizador__token_pattern': '\\\\w{1,}',\n",
       " 'estimator__vectorizador__tokenizer': None,\n",
       " 'estimator__vectorizador__use_idf': True,\n",
       " 'estimator__vectorizador__vocabulary': None,\n",
       " 'estimator__clf__C': 1.0,\n",
       " 'estimator__clf__class_weight': None,\n",
       " 'estimator__clf__dual': False,\n",
       " 'estimator__clf__fit_intercept': True,\n",
       " 'estimator__clf__intercept_scaling': 1,\n",
       " 'estimator__clf__l1_ratio': None,\n",
       " 'estimator__clf__max_iter': 100,\n",
       " 'estimator__clf__multi_class': 'auto',\n",
       " 'estimator__clf__n_jobs': None,\n",
       " 'estimator__clf__penalty': 'l2',\n",
       " 'estimator__clf__random_state': None,\n",
       " 'estimator__clf__solver': 'lbfgs',\n",
       " 'estimator__clf__tol': 0.0001,\n",
       " 'estimator__clf__verbose': 0,\n",
       " 'estimator__clf__warm_start': False,\n",
       " 'estimator': Pipeline(memory=None,\n",
       "          steps=[('vectorizador',\n",
       "                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                  decode_error='strict',\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  encoding='utf-8', input='content',\n",
       "                                  lowercase=True, max_df=1.0, max_features=None,\n",
       "                                  min_df=5, ngram_range=(1, 1), norm='l2',\n",
       "                                  preprocessor=None, smooth_idf=True,\n",
       "                                  stop_words='english', strip_accents='unicode',\n",
       "                                  sublinear_tf=False, token_pattern='\\\\w{1,}',\n",
       "                                  tokenizer=None, use_idf=True,\n",
       "                                  vocabulary=None)),\n",
       "                 ('clf',\n",
       "                  LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=100,\n",
       "                                     multi_class='auto', n_jobs=None,\n",
       "                                     penalty='l2', random_state=None,\n",
       "                                     solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                     warm_start=False))],\n",
       "          verbose=False),\n",
       " 'iid': 'deprecated',\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': {'clf__penalty': ['l1', 'l2'],\n",
       "  'clf__C': array([4. , 4.2, 4.4, 4.6, 4.8, 5. , 5.2])},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': 'accuracy',\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_7b.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(4,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bigramas más frecuentes para todos los tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " prueba de distintas alternativas, se comenzó con la idea de que tomar solo los bigramas más comunes iba a \n",
    " tener mejor desempeño que tomar todos ellos\n",
    " se fue jugando con la cantidad de bigramas buscando un valor óptimo que estaba en los 4370 bigramas\n",
    " no obstante siempre daba un peor score que tomando las palabras solas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76      4342\n",
      "           1       0.88      0.22      0.35      3271\n",
      "\n",
      "    accuracy                           0.65      7613\n",
      "   macro avg       0.75      0.60      0.56      7613\n",
      "weighted avg       0.73      0.65      0.58      7613\n",
      "\n",
      "Mejor Score:  0.20217665523425646\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', word_vectorizer_100),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81      4342\n",
      "           1       0.90      0.45      0.60      3271\n",
      "\n",
      "    accuracy                           0.74      7613\n",
      "   macro avg       0.80      0.70      0.70      7613\n",
      "weighted avg       0.78      0.74      0.72      7613\n",
      "\n",
      "Mejor Score:  0.30619222414261243\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', word_vectorizer_1000),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4342\n",
      "           1       0.99      0.95      0.97      3271\n",
      "\n",
      "    accuracy                           0.98      7613\n",
      "   macro avg       0.98      0.97      0.98      7613\n",
      "weighted avg       0.98      0.98      0.98      7613\n",
      "\n",
      "Mejor Score:  0.21345095872730924\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 23.7 ms, total: 1.13 s\n",
      "Wall time: 12.7 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85      4342\n",
      "           1       0.95      0.59      0.73      3271\n",
      "\n",
      "    accuracy                           0.81      7613\n",
      "   macro avg       0.85      0.78      0.79      7613\n",
      "weighted avg       0.84      0.81      0.80      7613\n",
      "\n",
      "Mejor Score:  0.248521157635411\n",
      "Mejores Parametros:  {'vectorizador__max_features': 4100}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(2000,5000,100)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 566 ms, sys: 4.24 ms, total: 571 ms\n",
      "Wall time: 4.43 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.86      4342\n",
      "           1       0.95      0.61      0.74      3271\n",
      "\n",
      "    accuracy                           0.82      7613\n",
      "   macro avg       0.86      0.79      0.80      7613\n",
      "weighted avg       0.85      0.82      0.81      7613\n",
      "\n",
      "Mejor Score:  0.24676726782176842\n",
      "Mejores Parametros:  {'vectorizador__max_features': 5000}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(5000,6000,100)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 s, sys: 30.4 ms, total: 1.7 s\n",
      "Wall time: 20.7 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86      4342\n",
      "           1       0.95      0.59      0.73      3271\n",
      "\n",
      "    accuracy                           0.81      7613\n",
      "   macro avg       0.85      0.79      0.79      7613\n",
      "weighted avg       0.84      0.81      0.80      7613\n",
      "\n",
      "Mejor Score:  0.2477282424514735\n",
      "Mejores Parametros:  {'vectorizador__max_features': 4350}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(4350,4400)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 605 ms, sys: 8.76 ms, total: 614 ms\n",
      "Wall time: 6.51 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      4342\n",
      "           1       0.97      0.90      0.93      3271\n",
      "\n",
      "    accuracy                           0.94      7613\n",
      "   macro avg       0.95      0.94      0.94      7613\n",
      "weighted avg       0.94      0.94      0.94      7613\n",
      "\n",
      "Mejor Score:  0.591367144990957\n",
      "Mejores Parametros:  {'vectorizador__max_features': 12000, 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { 'vectorizador__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'vectorizador__max_features': range(12000,15000,1000)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el mejor desempeño lo obtenemos con los ngramas de una sola palabra(monogramas), pero que no hay mejor desempeño con un límite de 12000 features que sin límite, esto se debe a que hay muchos mongramas que sólo se repiten una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bigramas más frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>suicide bomber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>northern california</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>oil spill</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>california wildfire</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>prime minister</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5082</th>\n",
       "      <td>could save</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8015</th>\n",
       "      <td>fully engulfed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17220</th>\n",
       "      <td>typhoon soudelors</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17221</th>\n",
       "      <td>soudelors predicted</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17222</th>\n",
       "      <td>predicted path</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     words  count\n",
       "15593       suicide bomber     60\n",
       "851    northern california     41\n",
       "13522            oil spill     38\n",
       "1536   california wildfire     36\n",
       "227         prime minister     36\n",
       "...                    ...    ...\n",
       "5082            could save      3\n",
       "8015        fully engulfed      3\n",
       "17220    typhoon soudelors      3\n",
       "17221  soudelors predicted      3\n",
       "17222       predicted path      3\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_true_tweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_true_tweets_list = bigrams_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 773 ms, sys: 3.72 ms, total: 777 ms\n",
      "Wall time: 904 ms\n",
      "Mejor Score:  0.14607029250753195\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2),vocabulary = bigrams_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { }\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuvamente el score de peor que antes se descarta esta opcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Trigramas más frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14862</th>\n",
       "      <td>suicide bomber detonated</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042</th>\n",
       "      <td>northern california wildfire</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13494</th>\n",
       "      <td>latest home razed</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>home razed northern</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14863</th>\n",
       "      <td>bomber detonated bomb</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16133</th>\n",
       "      <td>saw coach train</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16134</th>\n",
       "      <td>coach train plunging</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482</th>\n",
       "      <td>train derailment village</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>derailment village youth</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5484</th>\n",
       "      <td>village youth saved</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              words  count\n",
       "14862      suicide bomber detonated     30\n",
       "10042  northern california wildfire     29\n",
       "13494             latest home razed     28\n",
       "13495           home razed northern     28\n",
       "14863         bomber detonated bomb     28\n",
       "...                             ...    ...\n",
       "16133               saw coach train     12\n",
       "16134          coach train plunging     12\n",
       "5482       train derailment village     12\n",
       "5483       derailment village youth     12\n",
       "5484            village youth saved     12\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_true_tweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_true_tweets_list = trigrams_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 799 ms, sys: 4.01 ms, total: 803 ms\n",
      "Wall time: 907 ms\n",
      "Mejor Score:  0.09476591966494032\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(3,3),vocabulary = trigrams_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { }\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print()\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuevamente baja el score así que se descarta también esta opción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Palabras más frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_true_tweets_list = vocabulary_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.32 s, sys: 29.1 ms, total: 7.35 s\n",
      "Wall time: 9.63 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      4342\n",
      "           1       0.91      0.72      0.81      3271\n",
      "\n",
      "    accuracy                           0.85      7613\n",
      "   macro avg       0.86      0.83      0.84      7613\n",
      "weighted avg       0.86      0.85      0.85      7613\n",
      "\n",
      "Mejor Score:  0.5494148918074117\n",
      "Mejores Parametros:  {'clf__C': 0.09, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(vocabulary = vocabulary_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_true_tweets_orig_list = vocabulary_true_tweets_original.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.63 s, sys: 47 ms, total: 7.68 s\n",
      "Wall time: 9.62 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      4342\n",
      "           1       0.91      0.72      0.81      3271\n",
      "\n",
      "    accuracy                           0.85      7613\n",
      "   macro avg       0.86      0.83      0.84      7613\n",
      "weighted avg       0.86      0.85      0.85      7613\n",
      "\n",
      "Mejor Score:  0.5494148918074117\n",
      "Mejores Parametros:  {'clf__C': 0.09, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(vocabulary = vocabulary_true_tweets_orig_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4342\n",
      "           1       0.99      0.96      0.97      3271\n",
      "\n",
      "    accuracy                           0.98      7613\n",
      "   macro avg       0.98      0.98      0.98      7613\n",
      "weighted avg       0.98      0.98      0.98      7613\n",
      "\n",
      "Mejor Score:  0.7154919357413224\n",
      "Mejores Parametros:  {'clf__C': 4.2, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      4342\n",
      "           1       0.91      0.81      0.86      3271\n",
      "\n",
      "    accuracy                           0.88      7613\n",
      "   macro avg       0.89      0.87      0.88      7613\n",
      "weighted avg       0.89      0.88      0.88      7613\n",
      "\n",
      "Mejor Score:  0.6687325226940741\n",
      "Mejores Parametros:  {'clf__C': 4.0, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. combinacion tfidf + ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      4342\n",
      "           1       0.96      0.87      0.91      3271\n",
      "\n",
      "    accuracy                           0.93      7613\n",
      "   macro avg       0.93      0.92      0.93      7613\n",
      "weighted avg       0.93      0.93      0.93      7613\n",
      "\n",
      "Mejor Score:  0.710763992845575\n",
      "Mejores Parametros:  {'clf__C': 4.0}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('union',FeatureUnion([('vectorizador_tfidf',TfidfVectorizer(max_features = 10000)),\n",
    "                                            ('vectorizador_ngrams',CountVectorizer(ngram_range =(2,2),max_features=5 ))])),\n",
    "                              ('clf', LogisticRegression( max_iter=200))])\n",
    "\n",
    "grid_parametros = {'clf__C': np.arange(4,4.6,0.2)}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Seleccionando mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      4342\n",
      "           1       0.83      0.61      0.71      3271\n",
      "\n",
      "    accuracy                           0.78      7613\n",
      "   macro avg       0.79      0.76      0.77      7613\n",
      "weighted avg       0.79      0.78      0.77      7613\n",
      "\n",
      "Mejor Score:  0.673591785353446\n",
      "Mejores Parametros:  {'clf__C': 4.0}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),\n",
    "                              ('feature_selection', SelectKBest(chi2, k=200)),\n",
    "                              ('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__C': np.arange(4,5.2,0.2)}\n",
    "\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
