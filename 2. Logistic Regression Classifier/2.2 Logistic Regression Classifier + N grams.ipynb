{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/celeste/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/celeste/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/celeste/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 0 ns, total: 1.01 s\n",
      "Wall time: 1.01 s\n",
      "CPU times: user 46.1 ms, sys: 3.99 ms, total: 50.1 ms\n",
      "Wall time: 50.1 ms\n",
      "CPU times: user 71.3 ms, sys: 3 µs, total: 71.3 ms\n",
      "Wall time: 71.3 ms\n",
      "0\n",
      "CPU times: user 73.3 ms, sys: 0 ns, total: 73.3 ms\n",
      "Wall time: 73.2 ms\n",
      "CPU times: user 29.8 ms, sys: 3 µs, total: 29.8 ms\n",
      "Wall time: 29.9 ms\n",
      "CPU times: user 30.6 ms, sys: 0 ns, total: 30.6 ms\n",
      "Wall time: 30.6 ms\n",
      "CPU times: user 23.3 ms, sys: 0 ns, total: 23.3 ms\n",
      "Wall time: 23.2 ms\n"
     ]
    }
   ],
   "source": [
    "#Llamar al dataloader\n",
    "%run ../0_Data/1_DataLoaderNGRAMS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "#Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "#Tuning de Parametros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Clasificador\n",
    "from sklearn.linear_model import LogisticRegression # Classifier using Logistic Regression.\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Casos básicos de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 s, sys: 23.9 ms, total: 1.22 s\n",
      "Wall time: 24 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82       695\n",
      "           1       0.79      0.66      0.72       523\n",
      "\n",
      "    accuracy                           0.78      1218\n",
      "   macro avg       0.78      0.77      0.77      1218\n",
      "weighted avg       0.78      0.78      0.78      1218\n",
      "\n",
      "Mejor Score:  0.7526137378012453\n",
      "Mejores Parametros:  {'clf__C': 1.0, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.1,1.1,0.1),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_val_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_original, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 475 ms, sys: 313 µs, total: 475 ms\n",
      "Wall time: 5.85 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81       695\n",
      "           1       0.79      0.62      0.69       523\n",
      "\n",
      "    accuracy                           0.76      1218\n",
      "   macro avg       0.77      0.75      0.75      1218\n",
      "weighted avg       0.77      0.76      0.76      1218\n",
      "\n",
      "Mejor Score:  0.7879684094139947\n",
      "Mejores Parametros:  {'clf__C': 0.07999999999999999, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.06,0.08,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "%time clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_val_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_original, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       695\n",
      "           1       0.76      0.70      0.73       523\n",
      "\n",
      "    accuracy                           0.78      1218\n",
      "   macro avg       0.77      0.77      0.77      1218\n",
      "weighted avg       0.77      0.78      0.77      1218\n",
      "\n",
      "Mejor Score:  0.7879684094139947\n",
      "Mejores Parametros:  {'clf__C': 0.07999999999999999, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(4,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_val_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_original, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       695\n",
      "           1       0.76      0.70      0.73       523\n",
      "\n",
      "    accuracy                           0.78      1218\n",
      "   macro avg       0.77      0.77      0.77      1218\n",
      "weighted avg       0.77      0.78      0.77      1218\n",
      "\n",
      "Mejor Score:  0.7879684094139947\n",
      "Mejores Parametros:  {'clf__C': 0.07999999999999999, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(4,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_val_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_original, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bigramas más frecuentes para todos los tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " prueba de distintas alternativas, se comenzó con la idea de que tomar solo los bigramas más comunes iba a \n",
    " tener mejor desempeño que tomar todos ellos\n",
    " se fue jugando con la cantidad de bigramas buscando un valor óptimo que estaba en los 4370 bigramas\n",
    " no obstante siempre daba un peor score que tomando las palabras solas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       695\n",
      "           1       0.79      0.52      0.63       523\n",
      "\n",
      "    accuracy                           0.74      1218\n",
      "   macro avg       0.75      0.71      0.71      1218\n",
      "weighted avg       0.75      0.74      0.72      1218\n",
      "\n",
      "Mejor Score:  0.6457521550763345\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', word_vectorizer_100),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.78       695\n",
      "           1       0.80      0.42      0.55       523\n",
      "\n",
      "    accuracy                           0.71      1218\n",
      "   macro avg       0.74      0.67      0.67      1218\n",
      "weighted avg       0.73      0.71      0.68      1218\n",
      "\n",
      "Mejor Score:  0.5740653672641436\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', word_vectorizer_1000),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.80       695\n",
      "           1       0.85      0.48      0.62       523\n",
      "\n",
      "    accuracy                           0.74      1218\n",
      "   macro avg       0.78      0.71      0.71      1218\n",
      "weighted avg       0.77      0.74      0.72      1218\n",
      "\n",
      "Mejor Score:  0.6117976604896078\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 956 ms, sys: 19.9 ms, total: 976 ms\n",
      "Wall time: 11 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       695\n",
      "           1       0.79      0.51      0.62       523\n",
      "\n",
      "    accuracy                           0.73      1218\n",
      "   macro avg       0.75      0.70      0.71      1218\n",
      "weighted avg       0.74      0.73      0.72      1218\n",
      "\n",
      "Mejor Score:  0.6250886836881374\n",
      "Mejores Parametros:  {'vectorizador__max_features': 4900}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(2000,5000,100)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 467 ms, sys: 4.13 ms, total: 471 ms\n",
      "Wall time: 4.07 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       695\n",
      "           1       0.79      0.51      0.62       523\n",
      "\n",
      "    accuracy                           0.73      1218\n",
      "   macro avg       0.75      0.70      0.71      1218\n",
      "weighted avg       0.74      0.73      0.72      1218\n",
      "\n",
      "Mejor Score:  0.6278796864068091\n",
      "Mejores Parametros:  {'vectorizador__max_features': 5400}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(5000,6000,100)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 59.9 ms, total: 1.45 s\n",
      "Wall time: 18.5 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79       695\n",
      "           1       0.78      0.52      0.62       523\n",
      "\n",
      "    accuracy                           0.73      1218\n",
      "   macro avg       0.75      0.70      0.71      1218\n",
      "weighted avg       0.74      0.73      0.72      1218\n",
      "\n",
      "Mejor Score:  0.6209813098239051\n",
      "Mejores Parametros:  {'vectorizador__max_features': 4399}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(4350,4400)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { 'vectorizador__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'vectorizador__max_features': range(12000,15000,1000)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el mejor desempeño lo obtenemos con los ngramas de una sola palabra(monogramas), pero que no hay mejor desempeño con un límite de 12000 features que sin límite, esto se debe a que hay muchos mongramas que sólo se repiten una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bigramas más frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>in the</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>of the</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>play or</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>blow a</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>or blow</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>cdt by</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>for discoveri</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7741</th>\n",
       "      <td>a small</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>my god</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>of india</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              words  count\n",
       "241          in the     99\n",
       "315          of the     71\n",
       "763         play or     48\n",
       "765          blow a     48\n",
       "764         or blow     48\n",
       "...             ...    ...\n",
       "1345         cdt by      3\n",
       "1532  for discoveri      3\n",
       "7741        a small      3\n",
       "4421         my god      3\n",
       "4671       of india      3\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_true_tweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_true_tweets_list = bigrams_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 729 ms, sys: 3.89 ms, total: 733 ms\n",
      "Wall time: 830 ms\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.79       695\n",
      "           1       0.88      0.39      0.54       523\n",
      "\n",
      "    accuracy                           0.72      1218\n",
      "   macro avg       0.78      0.68      0.67      1218\n",
      "weighted avg       0.76      0.72      0.69      1218\n",
      "\n",
      "Mejor Score:  0.5298287822466191\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2),vocabulary = bigrams_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { }\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuvamente el score de peor que antes se descarta esta opcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Trigramas más frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>or blow a</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>play or blow</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>cheeki play or</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>out cheeki play</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>stick out cheeki</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>send a messag</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19167</th>\n",
       "      <td>need nuclear weapon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>in edinburgh are</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12556</th>\n",
       "      <td>deliv babi without</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>edinburgh are to</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     words  count\n",
       "727              or blow a     48\n",
       "726           play or blow     48\n",
       "725         cheeki play or     48\n",
       "724        out cheeki play     48\n",
       "723       stick out cheeki     48\n",
       "...                    ...    ...\n",
       "2034         send a messag      2\n",
       "19167  need nuclear weapon      2\n",
       "4871      in edinburgh are      2\n",
       "12556   deliv babi without      2\n",
       "4872      edinburgh are to      2\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_true_tweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_true_tweets_list = trigrams_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 784 ms, sys: 3.87 ms, total: 788 ms\n",
      "Wall time: 876 ms\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77       695\n",
      "           1       0.89      0.28      0.43       523\n",
      "\n",
      "    accuracy                           0.68      1218\n",
      "   macro avg       0.76      0.63      0.60      1218\n",
      "weighted avg       0.75      0.68      0.62      1218\n",
      "\n",
      "Mejor Score:  0.41516084661707486\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(3,3),vocabulary = trigrams_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { }\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuevamente baja el score así que se descarta también esta opción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Palabras más frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_true_tweets_list = vocabulary_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.54 s, sys: 15.9 ms, total: 5.55 s\n",
      "Wall time: 7.94 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       695\n",
      "           1       0.83      0.62      0.71       523\n",
      "\n",
      "    accuracy                           0.78      1218\n",
      "   macro avg       0.79      0.76      0.76      1218\n",
      "weighted avg       0.79      0.78      0.77      1218\n",
      "\n",
      "Mejor Score:  0.7298009736784803\n",
      "Mejores Parametros:  {'clf__C': 0.09, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(vocabulary = vocabulary_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_true_tweets_orig_list = vocabulary_true_tweets_original.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(vocabulary = vocabulary_true_tweets_orig_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. combinacion tfidf + ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       695\n",
      "           1       0.83      0.62      0.71       523\n",
      "\n",
      "    accuracy                           0.78      1218\n",
      "   macro avg       0.79      0.76      0.76      1218\n",
      "weighted avg       0.79      0.78      0.77      1218\n",
      "\n",
      "Mejor Score:  0.7298009736784803\n",
      "Mejores Parametros:  {'clf__C': 0.09, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('union',FeatureUnion([('vectorizador_tfidf',TfidfVectorizer(max_features = 10000)),\n",
    "                                            ('vectorizador_ngrams',CountVectorizer(ngram_range =(2,2),max_features=5 ))])),\n",
    "                              ('clf', LogisticRegression( max_iter=200))])\n",
    "\n",
    "grid_parametros = {'clf__C': np.arange(4,4.6,0.2)}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Seleccionando mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       695\n",
      "           1       0.83      0.62      0.71       523\n",
      "\n",
      "    accuracy                           0.78      1218\n",
      "   macro avg       0.79      0.76      0.76      1218\n",
      "weighted avg       0.79      0.78      0.77      1218\n",
      "\n",
      "Mejor Score:  0.7298009736784803\n",
      "Mejores Parametros:  {'clf__C': 0.09, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),\n",
    "                              ('feature_selection', SelectKBest(chi2, k=200)),\n",
    "                              ('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__C': np.arange(4,5.2,0.2)}\n",
    "\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_val_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_val_preprocesado, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
