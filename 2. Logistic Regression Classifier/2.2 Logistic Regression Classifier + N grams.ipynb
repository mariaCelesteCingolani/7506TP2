{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.42 s\n",
      "Wall time: 2.3 s\n",
      "Wall time: 2.06 s\n",
      "Wall time: 107 ms\n",
      "Wall time: 153 ms\n",
      "0\n",
      "Wall time: 148 ms\n",
      "Wall time: 68 ms\n",
      "Wall time: 75 ms\n",
      "Wall time: 53 ms\n"
     ]
    }
   ],
   "source": [
    "#Llamar al dataloader\n",
    "%run ../0_Data/1_DataLoaderNGRAMS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "#Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "#Tuning de Parametros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Clasificador\n",
    "from sklearn.linear_model import LogisticRegression # Classifier using Logistic Regression.\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Casos b√°sicos de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4342\n",
      "           1       0.99      0.93      0.96      3271\n",
      "\n",
      "    accuracy                           0.96      7613\n",
      "   macro avg       0.97      0.96      0.96      7613\n",
      "weighted avg       0.97      0.96      0.96      7613\n",
      "\n",
      "Mejor Score:  0.6381381725232763\n",
      "Mejores Parametros:  {'clf__C': 0.2, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.1,1.1,0.1),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      4342\n",
      "           1       0.91      0.75      0.82      3271\n",
      "\n",
      "    accuracy                           0.86      7613\n",
      "   macro avg       0.87      0.85      0.85      7613\n",
      "weighted avg       0.87      0.86      0.86      7613\n",
      "\n",
      "Mejor Score:  0.7313841292904333\n",
      "Mejores Parametros:  {'clf__C': 0.06999999999999999, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.06,0.08,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "%time clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4342\n",
      "           1       0.99      0.96      0.97      3271\n",
      "\n",
      "    accuracy                           0.98      7613\n",
      "   macro avg       0.98      0.98      0.98      7613\n",
      "weighted avg       0.98      0.98      0.98      7613\n",
      "\n",
      "Mejor Score:  0.7154919357413224\n",
      "Mejores Parametros:  {'clf__C': 4.2, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(4,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('vectorizador', TfidfVectorizer()),\n",
       "  ('clf', LogisticRegression())],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__vectorizador': TfidfVectorizer(),\n",
       " 'estimator__clf': LogisticRegression(),\n",
       " 'estimator__vectorizador__analyzer': 'word',\n",
       " 'estimator__vectorizador__binary': False,\n",
       " 'estimator__vectorizador__decode_error': 'strict',\n",
       " 'estimator__vectorizador__dtype': numpy.float64,\n",
       " 'estimator__vectorizador__encoding': 'utf-8',\n",
       " 'estimator__vectorizador__input': 'content',\n",
       " 'estimator__vectorizador__lowercase': True,\n",
       " 'estimator__vectorizador__max_df': 1.0,\n",
       " 'estimator__vectorizador__max_features': None,\n",
       " 'estimator__vectorizador__min_df': 1,\n",
       " 'estimator__vectorizador__ngram_range': (1, 1),\n",
       " 'estimator__vectorizador__norm': 'l2',\n",
       " 'estimator__vectorizador__preprocessor': None,\n",
       " 'estimator__vectorizador__smooth_idf': True,\n",
       " 'estimator__vectorizador__stop_words': None,\n",
       " 'estimator__vectorizador__strip_accents': None,\n",
       " 'estimator__vectorizador__sublinear_tf': False,\n",
       " 'estimator__vectorizador__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'estimator__vectorizador__tokenizer': None,\n",
       " 'estimator__vectorizador__use_idf': True,\n",
       " 'estimator__vectorizador__vocabulary': None,\n",
       " 'estimator__clf__C': 1.0,\n",
       " 'estimator__clf__class_weight': None,\n",
       " 'estimator__clf__dual': False,\n",
       " 'estimator__clf__fit_intercept': True,\n",
       " 'estimator__clf__intercept_scaling': 1,\n",
       " 'estimator__clf__l1_ratio': None,\n",
       " 'estimator__clf__max_iter': 100,\n",
       " 'estimator__clf__multi_class': 'auto',\n",
       " 'estimator__clf__n_jobs': None,\n",
       " 'estimator__clf__penalty': 'l2',\n",
       " 'estimator__clf__random_state': None,\n",
       " 'estimator__clf__solver': 'lbfgs',\n",
       " 'estimator__clf__tol': 0.0001,\n",
       " 'estimator__clf__verbose': 0,\n",
       " 'estimator__clf__warm_start': False,\n",
       " 'estimator': Pipeline(steps=[('vectorizador', TfidfVectorizer()),\n",
       "                 ('clf', LogisticRegression())]),\n",
       " 'iid': 'deprecated',\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': {'clf__penalty': ['l1', 'l2'],\n",
       "  'clf__C': array([4. , 4.2, 4.4, 4.6, 4.8, 5. , 5.2]),\n",
       "  'vectorizador__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': 'accuracy',\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_7b.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4342\n",
      "           1       0.99      0.96      0.97      3271\n",
      "\n",
      "    accuracy                           0.98      7613\n",
      "   macro avg       0.98      0.98      0.98      7613\n",
      "weighted avg       0.98      0.98      0.98      7613\n",
      "\n",
      "Mejor Score:  0.7154919357413224\n",
      "Mejores Parametros:  {'clf__C': 4.2, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(4,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bigramas m√°s frecuentes para todos los tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " prueba de distintas alternativas, se comenz√≥ con la idea de que tomar solo los bigramas m√°s comunes iba a \n",
    " tener mejor desempe√±o que tomar todos ellos\n",
    " se fue jugando con la cantidad de bigramas buscando un valor √≥ptimo que estaba en los 4370 bigramas\n",
    " no obstante siempre daba un peor score que tomando las palabras solas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76      4342\n",
      "           1       0.85      0.21      0.33      3271\n",
      "\n",
      "    accuracy                           0.64      7613\n",
      "   macro avg       0.74      0.59      0.54      7613\n",
      "weighted avg       0.72      0.64      0.57      7613\n",
      "\n",
      "Mejor Score:  0.28023531873408625\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', word_vectorizer_100),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81      4342\n",
      "           1       0.86      0.49      0.62      3271\n",
      "\n",
      "    accuracy                           0.74      7613\n",
      "   macro avg       0.78      0.71      0.71      7613\n",
      "weighted avg       0.77      0.74      0.73      7613\n",
      "\n",
      "Mejor Score:  0.4478463806007859\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', word_vectorizer_1000),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4342\n",
      "           1       0.99      0.96      0.98      3271\n",
      "\n",
      "    accuracy                           0.98      7613\n",
      "   macro avg       0.98      0.98      0.98      7613\n",
      "weighted avg       0.98      0.98      0.98      7613\n",
      "\n",
      "Mejor Score:  0.3800278678579739\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.8 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4342\n",
      "           1       0.94      0.71      0.81      3271\n",
      "\n",
      "    accuracy                           0.86      7613\n",
      "   macro avg       0.88      0.84      0.85      7613\n",
      "weighted avg       0.87      0.86      0.85      7613\n",
      "\n",
      "Mejor Score:  0.4275896260724732\n",
      "Mejores Parametros:  {'vectorizador__max_features': 4700}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(2000,5000,100)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(5000,6000,100)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(4350,4400)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { 'vectorizador__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'vectorizador__max_features': range(12000,15000,1000)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el mejor desempe√±o lo obtenemos con los ngramas de una sola palabra(monogramas), pero que no hay mejor desempe√±o con un l√≠mite de 12000 features que sin l√≠mite, esto se debe a que hay muchos mongramas que s√≥lo se repiten una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bigramas m√°s frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_true_tweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_true_tweets_list = bigrams_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2),vocabulary = bigrams_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { }\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuvamente el score de peor que antes se descarta esta opcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Trigramas m√°s frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_true_tweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_true_tweets_list = trigrams_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(3,3),vocabulary = trigrams_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { }\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print()\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuevamente baja el score as√≠ que se descarta tambi√©n esta opci√≥n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Palabras m√°s frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_true_tweets_list = vocabulary_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(vocabulary = vocabulary_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_true_tweets_orig_list = vocabulary_true_tweets_original.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(vocabulary = vocabulary_true_tweets_orig_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. combinacion tfidf + ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('union',FeatureUnion([('vectorizador_tfidf',TfidfVectorizer(max_features = 10000)),\n",
    "                                            ('vectorizador_ngrams',CountVectorizer(ngram_range =(2,2),max_features=5 ))])),\n",
    "                              ('clf', LogisticRegression( max_iter=200))])\n",
    "\n",
    "grid_parametros = {'clf__C': np.arange(4,4.6,0.2)}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Seleccionando mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),\n",
    "                              ('feature_selection', SelectKBest(chi2, k=200)),\n",
    "                              ('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__C': np.arange(4,5.2,0.2)}\n",
    "\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
