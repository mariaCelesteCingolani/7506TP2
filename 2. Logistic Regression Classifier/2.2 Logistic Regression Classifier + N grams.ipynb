{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.42 s\n",
      "Wall time: 2.3 s\n",
      "Wall time: 2.06 s\n",
      "Wall time: 107 ms\n",
      "Wall time: 153 ms\n",
      "0\n",
      "Wall time: 148 ms\n",
      "Wall time: 68 ms\n",
      "Wall time: 75 ms\n",
      "Wall time: 53 ms\n"
     ]
    }
   ],
   "source": [
    "#Llamar al dataloader\n",
    "%run ../0_Data/1_DataLoaderNGRAMS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "#Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "#Tuning de Parametros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Clasificador\n",
    "from sklearn.linear_model import LogisticRegression # Classifier using Logistic Regression.\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Casos básicos de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4342\n",
      "           1       0.99      0.93      0.96      3271\n",
      "\n",
      "    accuracy                           0.96      7613\n",
      "   macro avg       0.97      0.96      0.96      7613\n",
      "weighted avg       0.97      0.96      0.96      7613\n",
      "\n",
      "Mejor Score:  0.6381381725232763\n",
      "Mejores Parametros:  {'clf__C': 0.2, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.1,1.1,0.1),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      4342\n",
      "           1       0.91      0.75      0.82      3271\n",
      "\n",
      "    accuracy                           0.86      7613\n",
      "   macro avg       0.87      0.85      0.85      7613\n",
      "weighted avg       0.87      0.86      0.86      7613\n",
      "\n",
      "Mejor Score:  0.7313841292904333\n",
      "Mejores Parametros:  {'clf__C': 0.06999999999999999, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.06,0.08,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "%time clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4342\n",
      "           1       0.99      0.96      0.97      3271\n",
      "\n",
      "    accuracy                           0.98      7613\n",
      "   macro avg       0.98      0.98      0.98      7613\n",
      "weighted avg       0.98      0.98      0.98      7613\n",
      "\n",
      "Mejor Score:  0.7154919357413224\n",
      "Mejores Parametros:  {'clf__C': 4.2, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(4,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('vectorizador', TfidfVectorizer()),\n",
       "  ('clf', LogisticRegression())],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__vectorizador': TfidfVectorizer(),\n",
       " 'estimator__clf': LogisticRegression(),\n",
       " 'estimator__vectorizador__analyzer': 'word',\n",
       " 'estimator__vectorizador__binary': False,\n",
       " 'estimator__vectorizador__decode_error': 'strict',\n",
       " 'estimator__vectorizador__dtype': numpy.float64,\n",
       " 'estimator__vectorizador__encoding': 'utf-8',\n",
       " 'estimator__vectorizador__input': 'content',\n",
       " 'estimator__vectorizador__lowercase': True,\n",
       " 'estimator__vectorizador__max_df': 1.0,\n",
       " 'estimator__vectorizador__max_features': None,\n",
       " 'estimator__vectorizador__min_df': 1,\n",
       " 'estimator__vectorizador__ngram_range': (1, 1),\n",
       " 'estimator__vectorizador__norm': 'l2',\n",
       " 'estimator__vectorizador__preprocessor': None,\n",
       " 'estimator__vectorizador__smooth_idf': True,\n",
       " 'estimator__vectorizador__stop_words': None,\n",
       " 'estimator__vectorizador__strip_accents': None,\n",
       " 'estimator__vectorizador__sublinear_tf': False,\n",
       " 'estimator__vectorizador__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'estimator__vectorizador__tokenizer': None,\n",
       " 'estimator__vectorizador__use_idf': True,\n",
       " 'estimator__vectorizador__vocabulary': None,\n",
       " 'estimator__clf__C': 1.0,\n",
       " 'estimator__clf__class_weight': None,\n",
       " 'estimator__clf__dual': False,\n",
       " 'estimator__clf__fit_intercept': True,\n",
       " 'estimator__clf__intercept_scaling': 1,\n",
       " 'estimator__clf__l1_ratio': None,\n",
       " 'estimator__clf__max_iter': 100,\n",
       " 'estimator__clf__multi_class': 'auto',\n",
       " 'estimator__clf__n_jobs': None,\n",
       " 'estimator__clf__penalty': 'l2',\n",
       " 'estimator__clf__random_state': None,\n",
       " 'estimator__clf__solver': 'lbfgs',\n",
       " 'estimator__clf__tol': 0.0001,\n",
       " 'estimator__clf__verbose': 0,\n",
       " 'estimator__clf__warm_start': False,\n",
       " 'estimator': Pipeline(steps=[('vectorizador', TfidfVectorizer()),\n",
       "                 ('clf', LogisticRegression())]),\n",
       " 'iid': 'deprecated',\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': {'clf__penalty': ['l1', 'l2'],\n",
       "  'clf__C': array([4. , 4.2, 4.4, 4.6, 4.8, 5. , 5.2]),\n",
       "  'vectorizador__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': 'accuracy',\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_7b.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4342\n",
      "           1       0.99      0.96      0.97      3271\n",
      "\n",
      "    accuracy                           0.98      7613\n",
      "   macro avg       0.98      0.98      0.98      7613\n",
      "weighted avg       0.98      0.98      0.98      7613\n",
      "\n",
      "Mejor Score:  0.7154919357413224\n",
      "Mejores Parametros:  {'clf__C': 4.2, 'clf__penalty': 'l2', 'vectorizador__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(4,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bigramas más frecuentes para todos los tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " prueba de distintas alternativas, se comenzó con la idea de que tomar solo los bigramas más comunes iba a \n",
    " tener mejor desempeño que tomar todos ellos\n",
    " se fue jugando con la cantidad de bigramas buscando un valor óptimo que estaba en los 4370 bigramas\n",
    " no obstante siempre daba un peor score que tomando las palabras solas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76      4342\n",
      "           1       0.85      0.21      0.33      3271\n",
      "\n",
      "    accuracy                           0.64      7613\n",
      "   macro avg       0.74      0.59      0.54      7613\n",
      "weighted avg       0.72      0.64      0.57      7613\n",
      "\n",
      "Mejor Score:  0.28023531873408625\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', word_vectorizer_100),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81      4342\n",
      "           1       0.86      0.49      0.62      3271\n",
      "\n",
      "    accuracy                           0.74      7613\n",
      "   macro avg       0.78      0.71      0.71      7613\n",
      "weighted avg       0.77      0.74      0.73      7613\n",
      "\n",
      "Mejor Score:  0.4478463806007859\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', word_vectorizer_1000),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4342\n",
      "           1       0.99      0.96      0.98      3271\n",
      "\n",
      "    accuracy                           0.98      7613\n",
      "   macro avg       0.98      0.98      0.98      7613\n",
      "weighted avg       0.98      0.98      0.98      7613\n",
      "\n",
      "Mejor Score:  0.3800278678579739\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.8 s\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4342\n",
      "           1       0.94      0.71      0.81      3271\n",
      "\n",
      "    accuracy                           0.86      7613\n",
      "   macro avg       0.88      0.84      0.85      7613\n",
      "weighted avg       0.87      0.86      0.85      7613\n",
      "\n",
      "Mejor Score:  0.4275896260724732\n",
      "Mejores Parametros:  {'vectorizador__max_features': 4700}\n"
     ]
    }
   ],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(2000,5000,100)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(5000,6000,100)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2))),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = {'vectorizador__max_features': range(4350,4400)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { 'vectorizador__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'vectorizador__max_features': range(12000,15000,1000)}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el mejor desempeño lo obtenemos con los ngramas de una sola palabra(monogramas), pero que no hay mejor desempeño con un límite de 12000 features que sin límite, esto se debe a que hay muchos mongramas que sólo se repiten una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bigramas más frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_true_tweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_true_tweets_list = bigrams_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(2,2),vocabulary = bigrams_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { }\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuvamente el score de peor que antes se descarta esta opcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Trigramas más frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_true_tweets.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_true_tweets_list = trigrams_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(ngram_range =(3,3),vocabulary = trigrams_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "grid_parametros = { }\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print()\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuevamente baja el score así que se descarta también esta opción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Palabras más frecuentes para los tweets que son desastres naturales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_true_tweets_list = vocabulary_true_tweets.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(vocabulary = vocabulary_true_tweets_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_true_tweets_orig_list = vocabulary_true_tweets_original.words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer(vocabulary = vocabulary_true_tweets_orig_list )),('clf', LogisticRegression())])\n",
    "\n",
    "\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_ngrams_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "%time clf_1.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "\n",
    "pred_y = clf_1.predict(x_train_preprocesado)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. combinacion tfidf + ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('union',FeatureUnion([('vectorizador_tfidf',TfidfVectorizer(max_features = 10000)),\n",
    "                                            ('vectorizador_ngrams',CountVectorizer(ngram_range =(2,2),max_features=5 ))])),\n",
    "                              ('clf', LogisticRegression( max_iter=200))])\n",
    "\n",
    "grid_parametros = {'clf__C': np.arange(4,4.6,0.2)}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Seleccionando mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),\n",
    "                              ('feature_selection', SelectKBest(chi2, k=200)),\n",
    "                              ('clf', LogisticRegression())])\n",
    "\n",
    "grid_parametros = {'clf__C': np.arange(4,5.2,0.2)}\n",
    "\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='accuracy')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "pred_y = clf_7b.predict(x_train_original)\n",
    "print(\"Report: \\n{}\".format(classification_report(y_train, pred_y)))\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
