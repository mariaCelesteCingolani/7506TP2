{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7506 - Organizacion de Datos - TP NÂ°2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression  Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Librerias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.89 s\n",
      "Wall time: 2.54 s\n",
      "Wall time: 2.25 s\n",
      "Wall time: 119 ms\n",
      "Wall time: 163 ms\n",
      "0\n",
      "Wall time: 183 ms\n",
      "Wall time: 76 ms\n",
      "Wall time: 75 ms\n",
      "Wall time: 54 ms\n"
     ]
    }
   ],
   "source": [
    "%run ../0_Data/0_DataLoaderBOW_TFIDF.ipynb\n",
    "\n",
    "#Paquetes Clasicos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Tuning de Parametros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Clasificador\n",
    "from sklearn.linear_model import LogisticRegression # Classifier using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tfidf = Pipeline([('tfidf',TfidfVectorizer())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Pipeline BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bow_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Pipeline TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tfidf_LR = Pipeline([('vectorizador',TfidfVectorizer()),('clf', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tuning de Parametros - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 BOW - Texto sin Preprocesar - Vectorizador y Modelo sin optimizar Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score:  0.6253547761544995\n",
      "Mejores Parametros:  {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#No se setean variantes a los Hiperparametros\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_1.predict(x_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"original_bow_nohiper_logistic_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 BOW - Texto Preprocesado - Vectorizador y Modelo sin optimizar Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No se setean variantes a los Hiperparametros\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_2 = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_2.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_2.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_2.predict(x_test_preprocesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"preprocesado_bow_nohiper_logistic_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 BOW - Texto sin Preprocesar - Vectorizador y Modelo optimizando Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion a\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.1,1.1,0.1),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_3a = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_3a.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_3a.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_3a.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion b\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(1,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_3b = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_3b.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_3b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_3b.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion c\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_3c = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_3c.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_3c.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_3c.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion d\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.001,0.011,0.001),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_3d = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_3d.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_3d.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_3d.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion e\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.0001,0.0011,0.0001),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_3e = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_3e.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_3e.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_3e.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion f\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.001,0.011,0.001),\n",
    "                  'vectorizador__ngram_range': [(1,3),(1,4)]}\n",
    "                   \n",
    "clf_3f = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_3f.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_3f.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_3f.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion g\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.0001,0.0011,0.0001),\n",
    "                  'vectorizador__ngram_range': [(1,3),(1,4)]}\n",
    "                   \n",
    "clf_3g = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_3g.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_3g.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_3g.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_3a.predict(x_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"original_bow_hiper_logistic_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 BOW - Texto Preprocesado - Vectorizador y Modelo optimizando Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion a\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.1,1.1,0.1),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_4a = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_4a.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_4a.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_4a.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion b\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(1,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_4b = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_4b.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_4b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_4b.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion c\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_4c = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_4c.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_4c.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_4c.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion d\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.001,0.011,0.001),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_4d = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_4d.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_4d.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_4d.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion e\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.0001,0.0011,0.0001),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_4e = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_4e.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_4e.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_4e.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion f\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.001,0.011,0.001),\n",
    "                  'vectorizador__ngram_range': [(1,3),(1,4)]}\n",
    "                   \n",
    "clf_4f = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_4f.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_4f.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_4f.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion g\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.0001,0.0011,0.0001),\n",
    "                  'vectorizador__ngram_range': [(1,3),(1,4)]}\n",
    "                   \n",
    "clf_4g = GridSearchCV(pipeline_bow_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_4g.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_4g.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_4g.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_4a.predict(x_test_preprocesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"preprocesado_bow_hiper_logistic_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 TFIDF - Texto sin Preprocesar - Vectorizador y Modelo sin optimizar Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No se setean variantes a los Hiperparametros\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_5 = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_5.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_5.best_score_)\n",
    "print(\"Mojores Parametros: \", clf_5.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_5.predict(x_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"original_tfidf_nohiper_logistic_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 TFIDF - Texto Preprocesado - Vectorizador y Modelo sin optimizar Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No se setean variantes a los Hiperparametros\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_6 = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_6.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_6.best_score_)\n",
    "print(\"Mojores Parametros: \", clf_6.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_6.predict(x_test_preprocesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"preprocesado_tfidf_nohiper_logistic_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 TFIDF - Texto sin Preprocesar - Vectorizador y Modelo optimizando Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion a\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.1,1.1,0.1),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7a = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_7a.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_7a.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7a.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion b\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(1,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_7b.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_7b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7b.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion c\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7c = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_7c.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_7c.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7c.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion d\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.001,0.011,0.001),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7d = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_7d.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_7d.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7d.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion e\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.0001,0.0011,0.0001),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_7e = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_7e.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_7e.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7e.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion f\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.001,0.011,0.001),\n",
    "                  'vectorizador__ngram_range': [(1,3),(1,4)]}\n",
    "                   \n",
    "clf_7f = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_7f.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_7f.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7f.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion g\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.0001,0.0011,0.0001),\n",
    "                  'vectorizador__ngram_range': [(1,3),(1,4)]}\n",
    "                   \n",
    "clf_7g = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_7g.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_7g.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7g.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_7b.predict(x_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"original_tfidf_hiper_logistic_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 TFIDF - Texto Preprocesado - Vectorizador y Modelo optimizando Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion a\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.1,1.1,0.1),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_8a = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_8a.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_8a.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_8a.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion b\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(1,5.2,0.2),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_8b = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_8b.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_8b.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_8b.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion c\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.01,0.1,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_8c = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_8c.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_8c.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_8c.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion d\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.001,0.011,0.001),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_8d = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_8d.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_8d.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_8d.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion e\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.0001,0.0011,0.0001),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2),(1,3)]}\n",
    "                   \n",
    "clf_8e = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_8e.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_8e.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_8e.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion f\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.001,0.011,0.001),\n",
    "                  'vectorizador__ngram_range': [(1,3),(1,4)]}\n",
    "                   \n",
    "clf_8f = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_8f.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_8f.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_8f.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion g\n",
    "\n",
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.0001,0.0011,0.0001),\n",
    "                  'vectorizador__ngram_range': [(1,3),(1,4)]}\n",
    "                   \n",
    "clf_8g = GridSearchCV(pipeline_tfidf_LR, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_8g.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_8g.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_8g.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_8b.predict(x_test_preprocesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"preprocesado_tfidf_hiper_logistic_regression.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
