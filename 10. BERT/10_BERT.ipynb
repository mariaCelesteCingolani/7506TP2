{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --ignore-installed tensorflow-gpu --user\n",
    "# !pip install bert-for-tf2\n",
    "# !pip install --ignore-installed graphviz\n",
    "# !pip install --ignore-installed pydot\n",
    "# !pip install pydotplus\n",
    "# !pip install tf-models-nightly\n",
    "# !pip uninstall tf-nightly\n",
    "# !pip uninstall tf-estimator-nightly\n",
    "# !pip install kaggle\n",
    "# !pip install keras_lr_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\germa\\documents\\proyectos python\\tp1\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\germa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import kaggle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import compute_class_weight\n",
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "plt.rc('figure', figsize=(20,10))\n",
    "plt.rc('axes', labelsize=18, titlesize=20, titleweight = 'bold')    # tamaño de label y titulo \n",
    "plt.rc('xtick', labelsize=14)    # tamaño de los indicadores de variacion eje x\n",
    "plt.rc('ytick', labelsize=14)    # tamaño de los indicadores de variacion eje y\n",
    "plt.rc('legend', fontsize=14)    # tamaño del indicador (por ej, verdadero o falso)\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "%run ../0_Data/0_DataLoader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweets:\n",
    "    DATA_COLUMN = \"text\"\n",
    "    LABEL_COLUMN = \"target\"\n",
    "\n",
    "    def __init__(self, tokenizer: FullTokenizer, sample_size=None, max_seq_len=1024, train=None, test=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sample_size = sample_size\n",
    "        self.max_seq_len = 0\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        train = train[['text', 'target']].reset_index(drop=True)\n",
    "        test = test[['text', 'target']].reset_index(drop=True)\n",
    "        \n",
    "        ((self.train_x, self.train_y),\n",
    "         (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n",
    "        \n",
    "        print(\"max seq_len\", self.max_seq_len)\n",
    "        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "        ((self.train_x, self.train_x_token_types),\n",
    "         (self.test_x, self.test_x_token_types)) = map(self._pad, [self.train_x, self.test_x])\n",
    "\n",
    "    def _prepare(self, df):\n",
    "        x, y = [], []\n",
    "        with tqdm(total=df.shape[0], unit_scale=True) as pbar:\n",
    "            for ndx, row in df.iterrows():\n",
    "                text, label = row[Tweets.DATA_COLUMN], row[Tweets.LABEL_COLUMN]\n",
    "                tokens = self.tokenizer.tokenize(text)\n",
    "                tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "                token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "                self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "                x.append(token_ids)\n",
    "                y.append(int(label))\n",
    "                pbar.update()\n",
    "        return np.array(x), np.array(y)\n",
    "    \n",
    "    def _pad(self, ids):\n",
    "        x, t = [], []\n",
    "        token_type_ids = [0] * self.max_seq_len\n",
    "        for input_ids in ids:\n",
    "            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
    "            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
    "            x.append(np.array(input_ids))\n",
    "            t.append(token_type_ids)\n",
    "        return np.array(x), np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_ckpt_dir=\".models/uncased_L-12_H-768_A-12/\"\n",
    "bert_ckpt_file = bert_ckpt_dir + \"bert_model.ckpt\"\n",
    "bert_config_file = bert_ckpt_dir + \"bert_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layers(root_layer):\n",
    "    if isinstance(root_layer, keras.layers.Layer):\n",
    "        yield root_layer\n",
    "    for layer in root_layer._layers:\n",
    "        for sub_layer in flatten_layers(layer):\n",
    "            yield sub_layer\n",
    "\n",
    "\n",
    "def freeze_bert_layers(l_bert):\n",
    "    \"\"\"\n",
    "    Freezes all but LayerNorm and adapter layers - see arXiv:1902.00751.\n",
    "    \"\"\"\n",
    "    for layer in flatten_layers(l_bert):\n",
    "        if layer.name in [\"LayerNorm\", \"adapter-down\", \"adapter-up\"]:\n",
    "            layer.trainable = True\n",
    "        elif len(layer._layers) == 0:\n",
    "            layer.trainable = False\n",
    "        l_bert.embeddings_layer.trainable = False\n",
    "\n",
    "\n",
    "def create_learning_rate_scheduler(max_learn_rate=5e-5,\n",
    "                                   end_learn_rate=1e-7,\n",
    "                                   warmup_epoch_count=10,\n",
    "                                   total_epoch_count=90):\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        if epoch < warmup_epoch_count:\n",
    "            res = (max_learn_rate/warmup_epoch_count) * (epoch + 1)\n",
    "        else:\n",
    "            res = max_learn_rate*math.exp(math.log(end_learn_rate/max_learn_rate)*(epoch-warmup_epoch_count+1)/(total_epoch_count-warmup_epoch_count+1))\n",
    "        return float(res)\n",
    "    learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
    "\n",
    "    return learning_rate_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_seq_len, adapter_size=64):\n",
    "  # create the bert layer\n",
    "  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
    "      bc = StockBertConfig.from_json_string(reader.read())\n",
    "      bert_params = map_stock_config_to_params(bc)\n",
    "      bert_params.adapter_size = adapter_size\n",
    "      bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "        \n",
    "  input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\n",
    "  output         = bert(input_ids)\n",
    "\n",
    "  print(\"bert shape\", output.shape)\n",
    "  cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(output)\n",
    "  cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
    "  logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
    "  logits = keras.layers.Dropout(0.5)(logits)\n",
    "  logits = keras.layers.Dense(units=1, activation=None)(logits)\n",
    "\n",
    "  model = keras.Model(inputs=input_ids, outputs=logits)\n",
    "  model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "  # load the pre-trained model weights\n",
    "  load_stock_weights(bert, bert_ckpt_file)\n",
    "\n",
    "  if adapter_size is not None:\n",
    "      freeze_bert_layers(bert)\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "\n",
    "  model.summary()\n",
    "        \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.87k/4.87k [00:03<00:00, 1.62kit/s]\n",
      "<ipython-input-3-da32a5786367>:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(x), np.array(y)\n",
      "100%|██████████| 1.22k/1.22k [00:00<00:00, 1.66kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 82\n",
      "bert shape (None, 20, 768)\n",
      "loader: No value for:[bert/encoder/layer_0/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_0/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_0/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_0/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_0/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_0/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_0/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_0/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_0/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_0/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_0/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_0/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_0/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_0/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_0/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_0/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_1/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_1/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_1/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_1/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_1/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_1/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_1/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_1/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_1/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_1/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_1/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_1/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_1/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_1/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_1/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_1/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_2/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_2/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_2/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_2/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_2/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_2/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_2/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_2/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_2/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_2/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_2/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_2/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_2/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_2/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_2/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_2/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_3/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_3/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_3/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_3/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_3/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_3/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_3/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_3/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_3/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_3/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_3/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_3/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_3/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_3/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_3/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_3/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_4/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_4/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_4/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_4/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_4/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_4/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_4/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_4/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_4/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_4/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_4/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_4/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_4/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_4/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_4/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_4/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_5/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_5/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_5/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_5/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_5/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_5/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_5/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_5/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_5/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_5/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_5/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_5/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_5/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_5/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_5/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_5/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_6/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_6/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_6/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_6/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_6/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_6/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_6/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_6/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_6/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_6/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_6/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_6/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_6/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_6/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_6/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_6/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_7/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_7/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_7/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_7/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_7/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_7/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_7/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_7/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_7/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_7/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_7/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_7/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_7/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_7/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_7/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_7/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_8/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_8/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_8/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_8/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_8/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_8/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_8/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_8/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loader: No value for:[bert/encoder/layer_8/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_8/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_8/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_8/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_8/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_8/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_8/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_8/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_9/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_9/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_9/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_9/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_9/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_9/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_9/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_9/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_9/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_9/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_9/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_9/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_9/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_9/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_9/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_9/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_10/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_10/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_10/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_10/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_10/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_10/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_10/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_10/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_10/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_10/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_10/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_10/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_10/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_10/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_10/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_10/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_11/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_11/attention/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_11/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_11/attention/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_11/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_11/attention/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_11/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_11/attention/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_11/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_11/output/adapter-down/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_11/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_11/output/adapter-down/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_11/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_11/output/adapter-up/kernel] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "loader: No value for:[bert/encoder/layer_11/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_11/output/adapter-up/bias] in:[.models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "Done loading 196 BERT weights from: .models/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x00000208F5467DF0> (prefix:bert). Count of weights not found in the checkpoint was: [96]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 20, 768)           111269376 \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 111,860,737\n",
      "Trainable params: 3,007,489\n",
      "Non-trainable params: 108,853,248\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "  2/274 [..............................] - ETA: 42:15 - loss: 0.8454 - acc: 0.5938WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (9.265334). Check your callbacks.\n",
      "274/274 [==============================] - 63s 228ms/step - loss: 0.7580 - acc: 0.5575 - val_loss: 0.6205 - val_acc: 0.6967\n",
      "Epoch 2/5\n",
      "274/274 [==============================] - 36s 132ms/step - loss: 0.6762 - acc: 0.6350 - val_loss: 0.5602 - val_acc: 0.7439\n",
      "Epoch 3/5\n",
      "274/274 [==============================] - 36s 133ms/step - loss: 0.6247 - acc: 0.6829 - val_loss: 0.5533 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "274/274 [==============================] - 36s 132ms/step - loss: 0.6023 - acc: 0.7039 - val_loss: 0.5345 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "274/274 [==============================] - 36s 132ms/step - loss: 0.5782 - acc: 0.7281 - val_loss: 0.5272 - val_acc: 0.7684\n",
      "153/153 [==============================] - 19s 126ms/step - loss: 0.5208 - acc: 0.7594\n",
      "39/39 [==============================] - 5s 125ms/step - loss: 0.5565 - acc: 0.7365\n",
      "train acc 0.7594417333602905\n",
      " test acc 0.7364531755447388\n",
      "results [0.7364531755447388]\n",
      "Mean-Precision: 0.7364531755447388\n",
      "Wall time: 4min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "\n",
    "results = []\n",
    "history = 0\n",
    "def entrenar(train_df, val_df):\n",
    "    \n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    gc.collect()\n",
    "    \n",
    "    datos = get_data_original_as_database()\n",
    "    \n",
    "    data = Tweets(tokenizer, sample_size=None, max_seq_len=20, train=train_df, test=val_df)    \n",
    "    \n",
    "    model = create_model(data.max_seq_len, adapter_size=64)\n",
    "    \n",
    "    # model is a Keras model\n",
    "    lr_finder = LRFinder(model)\n",
    "    \n",
    "    # Train a model with batch size 512 for 5 epochs\n",
    "    # with learning rate growing exponentially from 0.0001 to 1\n",
    "#     lr_finder.find(data.train_x, data.train_y, start_lr=5.14e-6, end_lr=5.16e-6, batch_size=16, epochs=10)\n",
    "    # Plot the loss, ignore 20 batches in the beginning and 5 in the end\n",
    "#     lr_finder.plot_loss()\n",
    "    \n",
    "    log_dir = \".log/real_or_not/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    class_weights = compute_class_weight('balanced', np.unique(train_df.target), train_df.target) \n",
    "    class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    history = model.fit(x=data.train_x, y=data.train_y,\n",
    "              validation_split=0.1,\n",
    "              batch_size=16,\n",
    "              shuffle=True,\n",
    "              epochs=5,\n",
    "              class_weight = class_weights_dict,                        \n",
    "              callbacks=[tensorboard_callback, keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "\n",
    "# create_learning_rate_scheduler(max_learn_rate=2e-5,\n",
    "#                                                         end_learn_rate=1e-5,\n",
    "#                                                         warmup_epoch_count=20,\n",
    "#                                                         total_epoch_count=total_epoch_count),\n",
    "    \n",
    "    _, train_acc = model.evaluate(data.train_x, data.train_y)\n",
    "    _, test_acc = model.evaluate(data.test_x , data.test_y)\n",
    "    print(\"train acc\", train_acc)\n",
    "    print(\" test acc\", test_acc)\n",
    "    results.append(test_acc)\n",
    "    model.save_weights('./real_or_not.h5', overwrite=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    gc.collect()\n",
    "\n",
    "datos = get_data_original_as_database()\n",
    "\n",
    "test_data = datos.test\n",
    "train_df = datos.train\n",
    "val_data = datos.validation\n",
    "\n",
    "entrenar(train_df, val_data)\n",
    "\n",
    "# split, df_train, test_data = get_k_folded_data_original_as_database()\n",
    "\n",
    "# #Mantenemos los pesos de cada clase en cada K-Fold\n",
    "# for train_index, val_index in split:\n",
    "#     train_df = df_train.iloc[train_index]\n",
    "#     val_df = df_train.iloc[val_index]\n",
    "#     entrenar(train_df, val_df)\n",
    "\n",
    "    \n",
    "print(\"results\",results)\n",
    "print(f\"Mean-Precision: {sum(results) / len(results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# model.save_weights('./real_or_not.h5', overwrite=True)\n",
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))\n",
    "\n",
    "\n",
    "data = Tweets(tokenizer, sample_size=None, max_seq_len=20, train=train_df, test=test_data)    \n",
    "model = create_model(data.max_seq_len, adapter_size=64)\n",
    "model.load_weights(\"real_or_not.h5\")\n",
    "\n",
    "\n",
    "_, test_acc = model.evaluate(data.test_x, data.test_y)\n",
    "\n",
    "print(\"train acc\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    loss = history.history['loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(x, acc, 'r', label='Training acc')\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.title('Training accuracy vs loss')\n",
    "    plt.legend()\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))\n",
    "\n",
    "\n",
    "max_seq_len = 20\n",
    "max_seq_len1 = 0\n",
    "\n",
    "x, y = [], []\n",
    "for ndx, row in test_data.iterrows():\n",
    "    text = row['text']\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    max_seq_len1 = max(max_seq_len, len(token_ids))\n",
    "    x.append(token_ids)\n",
    "ids = np.array(x)\n",
    "max_seq_len = min(max_seq_len, max_seq_len1)\n",
    "\n",
    "x, t = [], []\n",
    "token_type_ids = [0] * max_seq_len\n",
    "for input_ids in ids:\n",
    "    input_ids = input_ids[:min(len(input_ids), max_seq_len - 2)]\n",
    "    input_ids = input_ids + [0] * (max_seq_len - len(input_ids))\n",
    "    x.append(np.array(input_ids))\n",
    "    t.append(token_type_ids)\n",
    "test_x, test_x_token_types = np.array(x), np.array(t)\n",
    "\n",
    "model = create_model(max_seq_len, adapter_size=64)\n",
    "model.load_weights(\"real_or_not.h5\")\n",
    "\n",
    "y_test = (model.predict(test_x, batch_size=16, verbose=1) > 0.5).astype(\"int32\")\n",
    "submission = pd.read_csv('../dataset/sample_submission.csv')\n",
    "submission['target'] = y_test\n",
    "submission.to_csv(\"submission3.csv\", index=False)\n",
    "\n",
    "# !kaggle competitions submit nlp-getting-started -f submission3.csv -m \"BERT submit 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.target.value_counts()/len(test_data.target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}