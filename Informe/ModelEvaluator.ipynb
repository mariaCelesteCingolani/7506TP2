{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/celeste/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/celeste/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/celeste/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%run ../0_Data/0_DataLoader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "#Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "#Tuning de Parametros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Clasificador\n",
    "from sklearn.linear_model import LogisticRegression # Classifier using Logistic Regression.\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, model, params, params_names ,data_x, data_y, clean_methods, metrics, metrics_names):\n",
    "        self.model = model\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.clean_methods = clean_methods\n",
    "        self.metrics = metrics\n",
    "        \n",
    "\n",
    "    def evaluate ():\n",
    "        \n",
    "        for clean_method in clean_methods:\n",
    "            if (clean_method != None):\n",
    "                data_x_clean = clean_method(data_x)\n",
    "            else:\n",
    "                data_x_clean = data_x\n",
    "            model.train(data_x_clean)\n",
    "            y_pred = model.predict(data_x_clean)\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (model, data_x, data_y, clean_methods, metrics):\n",
    "    \n",
    "    clean_names = []\n",
    "    for clean_method, cm_name in clean_methods:\n",
    "        if (clean_method != None):\n",
    "            clean_names.append(cm_name)\n",
    "        else:\n",
    "            clean_names.append('Ninguno')\n",
    "    metric_names = [m[1] for m in metrics]\n",
    "    columns = ['Modelo', 'Metodo de limpieza', 'Metrica', 'Valor'] \n",
    "    results = pd.DataFrame (columns = columns ) \n",
    "    \n",
    "    for clean_method, cm_name in clean_methods:\n",
    "            if (clean_method != None):\n",
    "                #print ('\\tMetodo de limpieza: ' + cm_name)\n",
    "                data_x_clean = data_x.apply(lambda x: clean_method(x))\n",
    "            else:\n",
    "                #print ('\\tMetodo de limpieza: Ninguno')\n",
    "                data_x_clean = data_x\n",
    "            model.train(data_x_clean, data_y)\n",
    "            y_pred = model.predict(data_x_clean)\n",
    "            \n",
    "            for metric, mname in metrics:\n",
    "                m = metric(data_y, y_pred)\n",
    "                #print ('\\t\\tMetrica ',mname, ': ',m)\n",
    "                df = pd.DataFrame([[model.getName(),cm_name,mname,m]], columns = columns)\n",
    "                results = results.append(df, ignore_index = True)\n",
    "                #print (df)\n",
    "    return results\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  1  2  3"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "columns = ['a', 'b', 'c']\n",
    "\n",
    "results = pd.DataFrame (columns = columns ) \n",
    "df = pd.DataFrame([[1,2,3]], columns = columns)\n",
    "results = results.append(df, ignore_index = True)\n",
    "results = results.append(df, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parametros = {'clf__penalty':['l1', 'l2'] ,\n",
    "                   'clf__C': np.arange(0.06,0.08,0.01),\n",
    "                  'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "lrm = LogisticRegressionModel(grid_parametros, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_methods = [(None, 'Ninguno'),(clean_text_sentiment_analysis, 'clean_text_sentiment_analysis'), (limpiar_texto, 'limpiar_texto'), (clean_text_simple,'clean_text_simple')]\n",
    "metrics = [(accuracy_score, 'Accuracy'),\n",
    "          (zero_one_loss, 'Loss'),\n",
    "          (f1_score, 'F1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel:\n",
    "    model = None\n",
    "    grid_params = None\n",
    "    params_description = None\n",
    "    \n",
    "    def __init__(self, grid_params , params_description):\n",
    "        self.grid_params = grid_params\n",
    "        self.params_description = params_description\n",
    "        \n",
    "    def getName(self):\n",
    "        return 'Logistic Regression ' + self.params_description\n",
    "    \n",
    "    def train(self, x, y):\n",
    "        pipeline_ngrams_LR = Pipeline([('vectorizador', CountVectorizer()),('clf', LogisticRegression())])\n",
    "        self.model = GridSearchCV(pipeline_ngrams_LR, self.grid_params,cv=5, n_jobs=-1)\n",
    "        self.model.fit(x, y)\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_original, train_y = get_train_x_y_original()\n",
    "\n",
    "x_test_original = get_test_x_original()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Metodo de limpieza</th>\n",
       "      <th>Metrica</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Ninguno</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.860633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Ninguno</td>\n",
       "      <td>Loss</td>\n",
       "      <td>0.139367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Ninguno</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.821771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>clean_text_sentiment_analysis</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.899120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>clean_text_sentiment_analysis</td>\n",
       "      <td>Loss</td>\n",
       "      <td>0.100880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>clean_text_sentiment_analysis</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.872383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>limpiar_texto</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.858663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>limpiar_texto</td>\n",
       "      <td>Loss</td>\n",
       "      <td>0.141337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>limpiar_texto</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.816257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>clean_text_simple</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.914357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>clean_text_simple</td>\n",
       "      <td>Loss</td>\n",
       "      <td>0.085643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>clean_text_simple</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.892763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Modelo             Metodo de limpieza   Metrica     Valor\n",
       "0   Logistic Regression                         Ninguno  Accuracy  0.860633\n",
       "1   Logistic Regression                         Ninguno      Loss  0.139367\n",
       "2   Logistic Regression                         Ninguno        F1  0.821771\n",
       "3   Logistic Regression   clean_text_sentiment_analysis  Accuracy  0.899120\n",
       "4   Logistic Regression   clean_text_sentiment_analysis      Loss  0.100880\n",
       "5   Logistic Regression   clean_text_sentiment_analysis        F1  0.872383\n",
       "6   Logistic Regression                   limpiar_texto  Accuracy  0.858663\n",
       "7   Logistic Regression                   limpiar_texto      Loss  0.141337\n",
       "8   Logistic Regression                   limpiar_texto        F1  0.816257\n",
       "9   Logistic Regression               clean_text_simple  Accuracy  0.914357\n",
       "10  Logistic Regression               clean_text_simple      Loss  0.085643\n",
       "11  Logistic Regression               clean_text_simple        F1  0.892763"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = evaluate(lrm, x_train_original, train_y, clean_methods, metrics )\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
