{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7506 - Organizacion de Datos - TP NÂ°2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Librerias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%run ../0_Data/0_DataLoaderBOW_TFIDF.ipynb\n",
    "\n",
    "#Paquetes Clasicos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Tuning de Parametros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Clasificador\n",
    "from sklearn.ensemble import RandomForestClassifier # Classifier using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tfidf = Pipeline([('tfidf',TfidfVectorizer())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Pipeline BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bow_random_forest = Pipeline([('vectorizador', CountVectorizer()),('clf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Pipeline TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tfidf_random_forest = Pipeline([('vectorizador',TfidfVectorizer()),('clf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tuning de Parametros - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 BOW - Texto sin Preprocesar - Vectorizador y Modelo sin optimizar Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score:  0.5170478444915039\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "#No se setean variantes a los Hiperparametros\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_bow_random_forest, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_1.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_1.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_1.predict(x_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"original_bow_nohiper_random_forest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 BOW - Texto Preprocesado - Vectorizador y Modelo sin optimizar Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score:  0.4915074679605777\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "#No se setean variantes a los Hiperparametros\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_2 = GridSearchCV(pipeline_bow_random_forest, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_2.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_2.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_2.predict(x_test_preprocesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"preprocesado_bow_nohiper_random_forest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 BOW - Texto sin Preprocesar - Vectorizador y Modelo optimizando Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score:  0.5648479156375631\n",
      "Mejores Parametros:  {'clf__criterion': 'gini', 'clf__n_estimators': 90, 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_parametros = {'clf__n_estimators': [90,100,110],\n",
    "                   'clf__criterion': ['gini', 'entropy'],\n",
    "                   'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "                   \n",
    "clf_3 = GridSearchCV(pipeline_bow_random_forest, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_3.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_3.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_3.predict(x_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"original_bow_hiper_random_forest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 BOW - Texto Preprocesado - Vectorizador y Modelo optimizando Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score:  0.5220939461598986\n",
      "Mejores Parametros:  {'clf__criterion': 'entropy', 'clf__n_estimators': 110, 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_parametros = {'clf__n_estimators': [90,100,110],\n",
    "                   'clf__criterion': ['gini', 'entropy'],\n",
    "                   'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "                   \n",
    "clf_4 = GridSearchCV(pipeline_bow_random_forest, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_4.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_4.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_4.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_4.predict(x_test_preprocesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"preprocesado_bow_hiper_random_forest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 TFIDF - Texto sin Preprocesar - Vectorizador y Modelo sin optimizar Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score:  0.5124045203663052\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "#No se setean variantes a los Hiperparametros\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_5 = GridSearchCV(pipeline_tfidf_random_forest, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_5.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_5.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_5.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_5.predict(x_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"original_tfidf_nohiper_random_forest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 TFIDF - Texto Preprocesado - Vectorizador y Modelo sin optimizar Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score:  0.5028608936054935\n",
      "Mejores Parametros:  {}\n"
     ]
    }
   ],
   "source": [
    "#No se setean variantes a los Hiperparametros\n",
    "\n",
    "grid_parametros = {}\n",
    "\n",
    "clf_6 = GridSearchCV(pipeline_tfidf_random_forest, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_6.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_6.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_6.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_6.predict(x_test_preprocesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"preprocesado_tfidf_nohiper_random_forest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 TFIDF - Texto sin Preprocesar - Vectorizador y Modelo optimizando Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score:  0.5784133536601057\n",
      "Mejores Parametros:  {'clf__criterion': 'gini', 'clf__n_estimators': 110, 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_parametros = {'clf__n_estimators': [90,100,110],\n",
    "                   'clf__criterion': ['gini', 'entropy'],\n",
    "                   'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "                   \n",
    "clf_7 = GridSearchCV(pipeline_tfidf_random_forest, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_7.fit(x_train_original, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_7.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_7.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_7.predict(x_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"original_tfidf_hiper_random_forest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 TFIDF - Texto Preprocesado - Vectorizador y Modelo optimizando Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Score:  0.5463259186103196\n",
      "Mejores Parametros:  {'clf__criterion': 'gini', 'clf__n_estimators': 110, 'vectorizador__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_parametros = {'clf__n_estimators': [90,100,110],\n",
    "                   'clf__criterion': ['gini', 'entropy'],\n",
    "                   'vectorizador__ngram_range': [(1,1),(1,2)]}\n",
    "                   \n",
    "clf_8 = GridSearchCV(pipeline_tfidf_random_forest, grid_parametros,cv=5, n_jobs=-1,scoring='f1')\n",
    "clf_8.fit(x_train_preprocesado, y_train)\n",
    "\n",
    "print(\"Mejor Score: \", clf_8.best_score_)\n",
    "print(\"Mejores Parametros: \", clf_8.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generacion del SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo el archivo .csv modelo que tenemos se utilizar para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nueva columna con los valores que predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = clf_8.predict(x_test_preprocesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo el archivo .csv para realizar el submit a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"preprocesado_tfidf_hiper_random_forest.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
